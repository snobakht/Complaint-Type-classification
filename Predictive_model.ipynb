{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data 311 a service that new york city residents use to give their complaints reports like noise, potholes ,.. to police from https://nycopendata.socrata.com/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify the type of complaint given the description written by people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/sama/spark-2.4.5-bin-hadoop2.7')\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import countDistinct\n",
    "from pyspark.sql.functions import unix_timestamp, from_unixtime, split\n",
    "from pyspark.sql.functions import year, month, hour\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoder, IndexToString, Word2Vec\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SR311_pred_model\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv file to spark dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"/home/user/Desktop/311.csv\", header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping irrelevant features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Complaint Type', 'Descriptor']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droping_attribs = [c for c in df.columns if c not in [\"Complaint Type\",\"Descriptor\"]]\n",
    "\n",
    "df = df.drop(*droping_attribs)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22340895"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.na.drop()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.sample(fraction = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1117161"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------------+\n",
      "|Complaint Type|Descriptor              |\n",
      "+--------------+------------------------+\n",
      "|HEAT/HOT WATER|APARTMENT ONLY          |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|APARTMENT ONLY          |\n",
      "|HEAT/HOT WATER|APARTMENT ONLY          |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|WATER LEAK    |DAMP SPOT               |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|DOOR/WINDOW   |WINDOW FRAME            |\n",
      "|DOOR/WINDOW   |WINDOW FRAME            |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING         |\n",
      "|PLUMBING      |WATER SUPPLY            |\n",
      "|PLUMBING      |WATER SUPPLY            |\n",
      "|SAFETY        |CARBON MONOXIDE DETECTOR|\n",
      "+--------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+------------------+------------------+--------------------+--------------------+\n",
      "|Complaint Type|     Descriptor|             words|             clean|            countvec|            features|\n",
      "+--------------+---------------+------------------+------------------+--------------------+--------------------+\n",
      "|HEAT/HOT WATER| APARTMENT ONLY| [apartment, only]|       [apartment]|   (1445,[21],[1.0])|(1445,[21],[3.903...|\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING|[entire, building]|[entire, building]|(1445,[3,7],[1.0,...|(1445,[3,7],[2.83...|\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING|[entire, building]|[entire, building]|(1445,[3,7],[1.0,...|(1445,[3,7],[2.83...|\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING|[entire, building]|[entire, building]|(1445,[3,7],[1.0,...|(1445,[3,7],[2.83...|\n",
      "|HEAT/HOT WATER|ENTIRE BUILDING|[entire, building]|[entire, building]|(1445,[3,7],[1.0,...|(1445,[3,7],[2.83...|\n",
      "+--------------+---------------+------------------+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_token = RegexTokenizer(inputCol=\"Descriptor\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "stopwords_remove = StopWordsRemover(inputCol=\"words\", outputCol=\"clean\")\n",
    "count_vectors = CountVectorizer(inputCol=\"clean\", outputCol=\"countvec\", vocabSize=10000, minDF=5)\n",
    "idf = IDF(inputCol=\"countvec\", outputCol=\"features\")\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[regex_token, stopwords_remove, count_vectors, idf]).fit(df)\n",
    "final_data = pipeline.transform(df)\n",
    "final_data.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert label to numerical index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelIndexer = StringIndexer(inputCol = \"Complaint Type\", outputCol = \"label\").fit(final_data)\n",
    "data = labelIndexer.transform(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split to tran and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_ = data.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = final_.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a logistic regression on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lr_model = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform test sat by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|         probability|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|[0.06654629112094...|171.0|       0.0|\n",
      "|[0.43170164563788...|  0.0|       0.0|\n",
      "|[0.43170164563788...| 17.0|       0.0|\n",
      "|[0.21031851655374...|  0.0|       0.0|\n",
      "|[0.47214307556650...|  0.0|       0.0|\n",
      "|[0.07461309686581...| 29.0|      29.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "|[0.03123214225314...|  1.0|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"probability\",\"label\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8621256844818872"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "7211a84a-8c57-41c6-8ae6-704693c1e84d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
